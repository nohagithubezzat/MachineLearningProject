{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8460798,"sourceType":"datasetVersion","datasetId":5043498}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# **CNN SCRATCH**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nimport cv2\nimport random\nimport glob as gb\nfrom collections import Counter\nfrom sklearn.metrics import classification_report\n\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import RMSprop\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score,precision_score, recall_score, f1_score\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:43:46.191527Z","iopub.execute_input":"2024-05-20T07:43:46.191891Z","iopub.status.idle":"2024-05-20T07:43:46.203453Z","shell.execute_reply.started":"2024-05-20T07:43:46.191861Z","shell.execute_reply":"2024-05-20T07:43:46.202491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"width = 224\nheight = 224\ncolor_channels = 3\nimage_size = (width, height, color_channels)\nnum_classes = 4\n\ntrain_path = '/kaggle/input/braintumor/Training'\ntest_path = '/kaggle/input/braintumor/Testing'\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:43:47.639409Z","iopub.execute_input":"2024-05-20T07:43:47.640126Z","iopub.status.idle":"2024-05-20T07:43:47.644963Z","shell.execute_reply.started":"2024-05-20T07:43:47.640079Z","shell.execute_reply":"2024-05-20T07:43:47.643792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_images_from_directory(folder_path, desc):\n\n    images = []\n    labels=[]\n\n    # Iterate through each folder in the given directory with a progress bar\n    i = 0\n    for folder in os.listdir(folder_path):\n        files = gb.glob(pathname=str(folder_path + '/' + folder + '/*.jpg'))\n\n        # For each file in the current folder, read the image and append its size\n        for file in tqdm(files, desc=desc+\" in \"+folder):\n            image = plt.imread(file)\n            img_resized=cv2.resize(image,(width,height))\n            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n            images.append(img_rgb)\n            labels.append(folder)\n\n\n\n    # Count the occurrence of each unique size\n    return images,labels\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:43:48.763247Z","iopub.execute_input":"2024-05-20T07:43:48.763961Z","iopub.status.idle":"2024-05-20T07:43:48.770688Z","shell.execute_reply.started":"2024-05-20T07:43:48.763930Z","shell.execute_reply":"2024-05-20T07:43:48.769732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train,y_train= read_images_from_directory(train_path, \"Loading Training Data\")","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:43:49.581282Z","iopub.execute_input":"2024-05-20T07:43:49.582079Z","iopub.status.idle":"2024-05-20T07:44:07.463975Z","shell.execute_reply.started":"2024-05-20T07:43:49.582051Z","shell.execute_reply":"2024-05-20T07:44:07.462904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test,y_test= read_images_from_directory(test_path, \"Loading Testing Data\")","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:44:08.835200Z","iopub.execute_input":"2024-05-20T07:44:08.835917Z","iopub.status.idle":"2024-05-20T07:44:12.606471Z","shell.execute_reply.started":"2024-05-20T07:44:08.835888Z","shell.execute_reply":"2024-05-20T07:44:12.605554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_data(list_of_images,labels):\n  plt.figure(figsize=(20,20))\n  for n,i in enumerate(list(np.random.randint(0,len(list_of_images),36))):\n      plt.subplot(6,6,n+1)\n      plt.imshow(list_of_images[i])\n      plt.axis('off')\n      plt.title(labels[i])","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:44:14.824947Z","iopub.execute_input":"2024-05-20T07:44:14.825317Z","iopub.status.idle":"2024-05-20T07:44:14.831650Z","shell.execute_reply.started":"2024-05-20T07:44:14.825287Z","shell.execute_reply":"2024-05-20T07:44:14.830543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_data(x_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:44:16.733950Z","iopub.execute_input":"2024-05-20T07:44:16.734691Z","iopub.status.idle":"2024-05-20T07:44:20.718620Z","shell.execute_reply.started":"2024-05-20T07:44:16.734661Z","shell.execute_reply":"2024-05-20T07:44:20.717268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = np.array(x_train)\nx_test = np.array(x_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\n\nprint(f'X_train shape  is {x_train.shape}')\nprint(f'X_test shape  is {x_test.shape}')\nprint(f'y_train shape  is {y_train.shape}')\nprint(f'y_test shape  is {y_test.shape}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:44:25.903657Z","iopub.execute_input":"2024-05-20T07:44:25.904047Z","iopub.status.idle":"2024-05-20T07:44:26.801319Z","shell.execute_reply.started":"2024-05-20T07:44:25.904017Z","shell.execute_reply":"2024-05-20T07:44:26.800215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:44:28.209593Z","iopub.execute_input":"2024-05-20T07:44:28.210227Z","iopub.status.idle":"2024-05-20T07:44:28.217044Z","shell.execute_reply.started":"2024-05-20T07:44:28.210195Z","shell.execute_reply":"2024-05-20T07:44:28.216152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_encoded = to_categorical(y_train_encoded)\ny_test_encoded = to_categorical(y_test_encoded)\n\nprint(y_train_encoded.shape)\nprint(y_test_encoded.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:44:29.471215Z","iopub.execute_input":"2024-05-20T07:44:29.471818Z","iopub.status.idle":"2024-05-20T07:44:29.477380Z","shell.execute_reply.started":"2024-05-20T07:44:29.471789Z","shell.execute_reply":"2024-05-20T07:44:29.476337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_custom_cnn(image_size, num_classes):\n    model = tf.keras.Sequential()\n\n    # First convolutional layer\n    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=image_size))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Dropout(0.25))  # Adding dropout\n\n    # Second convolutional layer\n    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Dropout(0.25))  # Adding dropout\n\n    model.add(layers.Flatten())\n\n    # Dense layers for classification\n    model.add(layers.Dense(256, activation='relu'))\n    model.add(layers.Dropout(0.5))  # Adding dropout\n    model.add(layers.Dense(num_classes, activation='softmax'))\n\n    # Compile the model\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n    # Print model summary\n    model.summary()\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:44:37.469380Z","iopub.execute_input":"2024-05-20T07:44:37.469956Z","iopub.status.idle":"2024-05-20T07:44:37.478346Z","shell.execute_reply.started":"2024-05-20T07:44:37.469927Z","shell.execute_reply":"2024-05-20T07:44:37.477335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"single_model = create_custom_cnn(image_size, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:44:39.652020Z","iopub.execute_input":"2024-05-20T07:44:39.652442Z","iopub.status.idle":"2024-05-20T07:44:39.763549Z","shell.execute_reply.started":"2024-05-20T07:44:39.652412Z","shell.execute_reply":"2024-05-20T07:44:39.762665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = single_model.fit(x_train, y_train_encoded, epochs=10, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:44:42.696559Z","iopub.execute_input":"2024-05-20T07:44:42.697267Z","iopub.status.idle":"2024-05-20T07:46:20.345289Z","shell.execute_reply.started":"2024-05-20T07:44:42.697237Z","shell.execute_reply":"2024-05-20T07:46:20.344338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_accuracy = single_model.evaluate(x_test, y_test_encoded)\n\nprint(f\"Test Accuracy: {test_accuracy}\")\nprint(f\"Test Loss: {test_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:48:00.999166Z","iopub.execute_input":"2024-05-20T07:48:00.999877Z","iopub.status.idle":"2024-05-20T07:48:02.853116Z","shell.execute_reply.started":"2024-05-20T07:48:00.999845Z","shell.execute_reply":"2024-05-20T07:48:02.852169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint('Training loss',np.mean(history.history['loss']))\nprint('Traing accuracy',np.mean(history.history['accuracy']))","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:48:05.029357Z","iopub.execute_input":"2024-05-20T07:48:05.030085Z","iopub.status.idle":"2024-05-20T07:48:05.035581Z","shell.execute_reply.started":"2024-05-20T07:48:05.030053Z","shell.execute_reply":"2024-05-20T07:48:05.034661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot training & validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:48:07.127258Z","iopub.execute_input":"2024-05-20T07:48:07.127940Z","iopub.status.idle":"2024-05-20T07:48:07.555462Z","shell.execute_reply.started":"2024-05-20T07:48:07.127909Z","shell.execute_reply":"2024-05-20T07:48:07.554509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = single_model.predict(x_test)\ny_pred = np.argmax(predictions, axis=1)\ny_true = np.argmax(y_test_encoded, axis=1)\n\nprint(classification_report(y_true, y_pred))\nprecision = precision_score(y_true, y_pred, average='weighted')\nrecall = recall_score(y_true, y_pred, average='weighted')\nf1 = f1_score(y_true, y_pred, average='weighted')\nprint('Accuracy:', accuracy_score(y_true, y_pred))\n# Print metrics\nprint('Precision:', precision)\nprint('Recall:', recall)\nprint('F1-Score:', f1)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:48:09.617848Z","iopub.execute_input":"2024-05-20T07:48:09.618252Z","iopub.status.idle":"2024-05-20T07:48:11.158617Z","shell.execute_reply.started":"2024-05-20T07:48:09.618221Z","shell.execute_reply":"2024-05-20T07:48:11.157675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **VGG16**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\ndef create_vgg(image_size, num_classes):\n    \"\"\"\n    Creates, compiles, prints a summary, and visualizes a model with VGG16 as the base.\n\n    Parameters:\n    - image_size: tuple, the input size of the images (height, width, channels).\n    - num_classes: int, the number of classes for the classification task.\n\n    Returns:\n    - The compiled model.\n    \"\"\"\n\n    # Load pre-trained VGG16 model + higher level layers\n    vgg = tf.keras.applications.VGG16(\n        include_top=False,  # Exclude the top classification layer\n        weights=\"imagenet\",\n        input_shape=image_size\n    )\n\n    # Freeze layers in the base model\n    for layer in vgg.layers:\n        layer.trainable = False\n\n    # Create a sequential model\n    model = models.Sequential()\n\n    # Add the base model\n    model.add(vgg)\n\n    # Add a global max pooling layer\n    model.add(layers.GlobalMaxPooling2D())\n\n    # Add final classification layers\n    model.add(layers.Dense(256, activation='relu'))\n    model.add(layers.Dense(num_classes, activation='softmax'))\n\n    # Compile the model\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n    # Build the model by providing input shape\n    model.build(input_shape=(None,) + image_size)\n\n    # Print model summary\n    model.summary()\n\n    # Visualize the model\n    visualization_path = 'model_visualization.png'\n    tf.keras.utils.plot_model(model, to_file=visualization_path, show_shapes=True, show_layer_names=True)\n\n    print(f\"Model visualization saved to {visualization_path}\")\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T08:03:30.460872Z","iopub.execute_input":"2024-05-20T08:03:30.461613Z","iopub.status.idle":"2024-05-20T08:03:30.470871Z","shell.execute_reply.started":"2024-05-20T08:03:30.461581Z","shell.execute_reply":"2024-05-20T08:03:30.469745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"single_model =create_vgg(image_size, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:48:29.124421Z","iopub.execute_input":"2024-05-20T07:48:29.125017Z","iopub.status.idle":"2024-05-20T07:48:29.570564Z","shell.execute_reply.started":"2024-05-20T07:48:29.124987Z","shell.execute_reply":"2024-05-20T07:48:29.569614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = single_model.fit(x_train, y_train_encoded, epochs=10, validation_split=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:48:32.980226Z","iopub.execute_input":"2024-05-20T07:48:32.980895Z","iopub.status.idle":"2024-05-20T07:52:39.205994Z","shell.execute_reply.started":"2024-05-20T07:48:32.980861Z","shell.execute_reply":"2024-05-20T07:52:39.205147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_accuracy = single_model.evaluate(x_test, y_test_encoded)\n\nprint(f\"Test Accuracy: {test_accuracy}\")\nprint(f\"Test Loss: {test_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:53:25.135908Z","iopub.execute_input":"2024-05-20T07:53:25.136564Z","iopub.status.idle":"2024-05-20T07:53:36.119420Z","shell.execute_reply.started":"2024-05-20T07:53:25.136533Z","shell.execute_reply":"2024-05-20T07:53:36.118426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-20T08:03:06.325615Z","iopub.execute_input":"2024-05-20T08:03:06.325971Z","iopub.status.idle":"2024-05-20T08:03:06.364300Z","shell.execute_reply.started":"2024-05-20T08:03:06.325943Z","shell.execute_reply":"2024-05-20T08:03:06.363122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Inception**","metadata":{}},{"cell_type":"code","source":"# Load EfficientNetB0 base model\nbase_model = tf.keras.applications.EfficientNetB0(weights='imagenet', include_top=False, input_shape=(height, width, color_channels))\n\n# Count the total number of layers in the base model\ntotal_layers = len(base_model.layers)\n\n# Freeze all layers except the last 10\nfor layer in base_model.layers[:-10]:\n    layer.trainable = False\n\n# Create a Sequential model\nmodel = tf.keras.Sequential()\n\n# Add the EfficientNetB0 base model\nmodel.add(base_model)\n\n# Add global pooling and flatten layers\nmodel.add(layers.GlobalMaxPooling2D())\nmodel.add(layers.Flatten())\n\n# Add dense layers\nmodel.add(layers.Dense(256, activation='relu'))\n\n# Output layer\nmodel.add(layers.Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Early stopping callback\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy', \n    min_delta=0.001,        # Minimum change to qualify as an improvement\n    patience=3,             # Number of epochs to wait for improvement\n    verbose=1,              # Verbosity mode\n    restore_best_weights=True # Restore the best weights after stopping\n)\n\n# Train the model\nhistory = model.fit(\n    x_train, y_train_encoded, \n    epochs=15, \n    validation_split=0.2, \n    callbacks=[early_stopping]\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Res101**","metadata":{}},{"cell_type":"code","source":"\ndef create_resnet101(image_size, num_classes):\n    \"\"\"\n    Creates, compiles, prints a summary, and visualizes a model with MobileNetV3Small and ResNet101 branches.\n\n    Parameters:\n    - image_size: tuple, the input size of the images (height, width, channels).\n    - num_classes: int, the number of classes for the classification task.\n\n    Returns:\n    - The compiled model.\n    \"\"\"\n    # Load pre-trained models\n    res101 = tf.keras.applications.ResNet101(include_top=False,\n                                             weights='imagenet',\n                                             input_shape=image_size)\n\n    # Freeze layers in the base model\n    for layer in res101.layers:\n        layer.trainable = False\n\n    # Create a sequential model\n    model = tf.keras.Sequential()\n\n    # Add the base model\n    model.add(res101)\n\n    # Add a global max pooling layer\n    model.add(layers.GlobalMaxPooling2D())\n\n    # Add a flatten layer\n    model.add(layers.Flatten())\n\n    # Add final classification layers\n    model.add(layers.Dense(256, activation='relu'))\n    model.add(layers.Dense(num_classes, activation='softmax'))\n\n    # Compile the model\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n    # Print model summary\n    model.summary()\n\n    # Visualize the model\n    visualization_path = 'model_visualization.png'\n    tf.keras.utils.plot_model(model, to_file=visualization_path, show_shapes=True, show_layer_names=True)\n\n    print(f\"Model visualization saved to {visualization_path}\")\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:58:38.039531Z","iopub.execute_input":"2024-05-20T07:58:38.039914Z","iopub.status.idle":"2024-05-20T07:58:38.048913Z","shell.execute_reply.started":"2024-05-20T07:58:38.039886Z","shell.execute_reply":"2024-05-20T07:58:38.047993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}